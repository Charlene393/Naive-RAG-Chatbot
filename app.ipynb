{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi6S4AYoe3EkjKuak5gkL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Charlene393/Naive-RAG-Chatbot/blob/main/app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p-HPjlU7f1pn"
      },
      "outputs": [],
      "source": [
        "#Import packages\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "import pandas as pd\n",
        "import base64\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import for langchain\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "DRNW0CjFgzTb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get text chunks from pdf\n",
        "\n",
        "def get_pdf_text(pdf_document):\n",
        "  text =\"\"\n",
        "  for pdf in pdf_document:\n",
        "    pdf_reader = PdfReader(pdf)\n",
        "    for page in pdf_reader.pages:\n",
        "      text += page.extract_text()\n",
        "  return text"
      ],
      "metadata": {
        "id": "jzXa_R5riM8u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get chunks from texts\n",
        "def get_text_chunks(text, model_name):\n",
        "  if model_name == \"Google AI\":\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size =1000,\n",
        "        chunk_overlap = 1000)\n",
        "    chunks = text_splitter.split_text(text)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "lu1-NyqvkRfg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunks embedding and storing them in a vector store:\n",
        "def get_vectorstore(text_chunk, model_name, api_key = None):\n",
        "  if model_name == \"Google AI\":\n",
        "    embeddings = GoogleGenerativeAIEmbeddings(\n",
        "        model= \"models/embedding-001\",\n",
        "        google_api_key = api_key)\n",
        "    vectorstore = FAISS.from_texts(texts = text_chunk, embedding = embeddings)\n",
        "    return vectorstore"
      ],
      "metadata": {
        "id": "pFZjmLWpls6I"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a conversational chain using langchain\n",
        "def get_conversational_chain(model_name, vectorstore=None, api_key= None):\n",
        "  if model_name ==\"Google AI\":\n",
        "    prompt_template=\"\"\"\n",
        "      Answer the question as detailed as possible from the provided context, make sure to provide all the details\n",
        "      with proper structure, if the answer is not in the provided context just say, \"Answer is not available in\n",
        "      the context\", don't provide wrong answer \\n\\n\n",
        "      Context:\\n {context}?\\n\n",
        "      Question:\\n {question}?\\n\n",
        "\n",
        "      Answer:\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "    model = ChatGoogleGenerativeAI(\n",
        "        model = \"gemini-1.5-flash\",\n",
        "        temperature = 0.3,\n",
        "        google_api_key = api_key)\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        template = prompt_template,\n",
        "        input_variables = [\"context\", \"question\"])\n",
        "    chain = load_qa_chain(model, chain_type= \"stuff\", prompt = prompt)\n",
        "\n",
        "\n",
        "    return chain"
      ],
      "metadata": {
        "id": "wIaO2s8BmjJg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Take user input\n",
        "\n",
        "def user_input(user_question, model_name, api_key, pdf_docs, conversation_history):\n",
        "  if api_key is None or pdf_docs is None:\n",
        "    st.warning(\"Please provide both API key and PDF documents.\")\n",
        "    return\n",
        "  text_chunks = get_text_chunks(get_pdf_text(pdf_docs), model_name)\n",
        "  vector_store = get_vectorstore(text_chunks, model_name, api_key)\n",
        "  user_queestion_output = \"\"\n",
        "  response_output = \"\"\n",
        "  if model_name == \"Google AI\":\n",
        "    embedding = GoogleGenerativeAIEmbeddings(\n",
        "        model_name = \"models/embedding-001\",\n",
        "        google_api_key = api_key)\n",
        "    new_db = FAISS.load_local(\"faiss_index\", embedding, allow_dangerous_deserialization= True)\n",
        "    docs = new_db.similarity_search( user_question)\n",
        "\n",
        "    chain = get_conversational_chain(\"Google AI\", vectorstore=new_db, api_key=api_key)\n",
        "    response = chain({\"input_documents\":docs,\n",
        "                      \"question\": user_question},\n",
        "                     return_only_outputs=True)\n",
        "    user_queestion_output = user_question\n",
        "    response_output = response[\"output_text\"]\n",
        "    pdf_names = [pdf.name for pdf in pdf_docs] if pdf_docs else []\n",
        "    conversation_history.append((user_queestion_output, response_output, model_name, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), \",\".join(pdf_names)))\n",
        "\n",
        "\n",
        "  st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "            .chat-message {{\n",
        "                padding: 1.5rem;\n",
        "                border-radius: 0.5rem;\n",
        "                margin-bottom: 1rem;\n",
        "                display: flex;\n",
        "            }}\n",
        "            .chat-message.user {{\n",
        "                background-color: #2b313e;\n",
        "            }}\n",
        "            .chat-message.bot {{\n",
        "                background-color: #475063;\n",
        "            }}\n",
        "            .chat-message .avatar {{\n",
        "                width: 20%;\n",
        "            }}\n",
        "            .chat-message .avatar img {{\n",
        "                max-width: 78px;\n",
        "                max-height: 78px;\n",
        "                border-radius: 50%;\n",
        "                object-fit: cover;\n",
        "            }}\n",
        "            .chat-message .message {{\n",
        "                width: 80%;\n",
        "                padding: 0 1.5rem;\n",
        "                color: #fff;\n",
        "            }}\n",
        "            .chat-message .info {{\n",
        "                font-size: 0.8rem;\n",
        "                margin-top: 0.5rem;\n",
        "                color: #ccc;\n",
        "            }}\n",
        "        </style>\n",
        "        <div class=\"chat-message user\">\n",
        "            <div class=\"avatar\">\n",
        "                <img src=\"https://i.ibb.co/CKpTnWr/user-icon-2048x2048-ihoxz4vq.png\">\n",
        "            </div>\n",
        "            <div class=\"message\">{user_question_output}</div>\n",
        "        </div>\n",
        "        <div class=\"chat-message bot\">\n",
        "            <div class=\"avatar\">\n",
        "                <img src=\"https://i.ibb.co/wNmYHsx/langchain-logo.webp\" >\n",
        "            </div>\n",
        "            <div class=\"message\">{response_output}</div>\n",
        "            </div>\n",
        "\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "\n",
        "  )\n",
        "\n",
        "\n",
        "  if len(conversation_history) == 1:\n",
        "    conversation_history =[]\n",
        "\n",
        "  elif len(conversation_history)>1:\n",
        "    last_item = conversation_history[-1]\n",
        "    conversation_history.remove(last_item)\n",
        "\n",
        "  for question, answer, model_name, timestamp, pdf_name in reversed(conversation_history):\n",
        "    st.markdown(\n",
        "            f\"\"\"\n",
        "            <div class=\"chat-message user\">\n",
        "                <div class=\"avatar\">\n",
        "                    <img src=\"https://i.ibb.co/CKpTnWr/user-icon-2048x2048-ihoxz4vq.png\">\n",
        "                </div>\n",
        "                <div class=\"message\">{question}</div>\n",
        "            </div>\n",
        "            <div class=\"chat-message bot\">\n",
        "                <div class=\"avatar\">\n",
        "                    <img src=\"https://i.ibb.co/wNmYHsx/langchain-logo.webp\" >\n",
        "                </div>\n",
        "                <div class=\"message\">{answer}</div>\n",
        "            </div>\n",
        "            \"\"\",\n",
        "            unsafe_allow_html=True\n",
        "        )\n",
        "\n",
        "    df = pd.DataFrame(st.session_state.conversation_history, columns=[\"Question\", \"Answer\", \"Model\", \"Timestamp\", \"PDF Name\"])\n",
        "\n",
        "    # df = pd.DataFrame(st.session_state.conversation_history, columns=[\"Question\", \"Answer\", \"Timestamp\", \"PDF Name\"])\n",
        "    csv = df.to_csv(index=False)\n",
        "    b64 = base64.b64encode(csv.encode()).decode()  # Convert to base64\n",
        "    href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"conversation_history.csv\"><button>Download conversation history as CSV file</button></a>'\n",
        "    st.sidebar.markdown(href, unsafe_allow_html=True)\n",
        "    st.markdown(\"To download the conversation, click the Download button on the left side at the bottom of the conversation.\")\n",
        "st.snow()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KKu5czdr16r",
        "outputId": "9049d273-7718-40ff-8f83-c855ce1d5831"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-20 09:31:31.273 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:31:31.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:31:31.275 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    st.set_page_config(page_title=\"Chat with multiple PDFs\", page_icon=\":books:\")\n",
        "    st.header(\"Chat with multiple PDFs (v1) :books:\")\n",
        "\n",
        "    if 'conversation_history' not in st.session_state:\n",
        "        st.session_state.conversation_history = []\n",
        "    linkedin_profile_link = \"https://www.linkedin.com/in/charlene-mbugua\"\n",
        "    kaggle_profile_link = \"https://www.kaggle.com/charlenembugua\"\n",
        "    github_profile_link = \"https://github.com/Charlene393\"\n",
        "\n",
        "    st.sidebar.markdown(\n",
        "        f\"[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)]({linkedin_profile_link}) \"\n",
        "        f\"[![Kaggle](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)]({kaggle_profile_link}) \"\n",
        "        f\"[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)]({github_profile_link})\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    model_name = st.sidebar.radio(\"Select the Model:\", ( \"Google AI\"))\n",
        "\n",
        "    api_key = None\n",
        "\n",
        "    if model_name == \"Google AI\":\n",
        "        api_key = st.sidebar.text_input(\"Enter your Google API Key:\")\n",
        "        st.sidebar.markdown(\"Click [here](https://ai.google.dev/) to get an API key.\")\n",
        "\n",
        "        if not api_key:\n",
        "            st.sidebar.warning(\"Please enter your Google API Key to proceed.\")\n",
        "            return\n",
        "\n",
        "\n",
        "    with st.sidebar:\n",
        "        st.title(\"Menu:\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        reset_button = col2.button(\"Reset\")\n",
        "        clear_button = col1.button(\"Rerun\")\n",
        "\n",
        "        if reset_button:\n",
        "            st.session_state.conversation_history = []  # Clear conversation history\n",
        "            st.session_state.user_question = None  # Clear user question input\n",
        "\n",
        "\n",
        "            api_key = None  # Reset Google API key\n",
        "            pdf_docs = None  # Reset PDF document\n",
        "\n",
        "        else:\n",
        "            if clear_button:\n",
        "                if 'user_question' in st.session_state:\n",
        "                    st.warning(\"The previous query will be discarded.\")\n",
        "                    st.session_state.user_question = \"\"  # Temizle\n",
        "                    if len(st.session_state.conversation_history) > 0:\n",
        "                        st.session_state.conversation_history.pop()  # Son sorguyu kaldır\n",
        "                else:\n",
        "                    st.warning(\"The question in the input will be queried again.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        pdf_docs = st.file_uploader(\"Upload your PDF Files and Click on the Submit & Process Button\", accept_multiple_files=True)\n",
        "        if st.button(\"Submit & Process\"):\n",
        "            if pdf_docs:\n",
        "                with st.spinner(\"Processing...\"):\n",
        "                    st.success(\"Done\")\n",
        "            else:\n",
        "                st.warning(\"Please upload PDF files before processing.\")\n",
        "\n",
        "    user_question = st.text_input(\"Ask a Question from the PDF Files\")\n",
        "\n",
        "    if user_question:\n",
        "        user_input(user_question, model_name, api_key, pdf_docs, st.session_state.conversation_history)\n",
        "        st.session_state.user_question = \"\"  # Clear user question input\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEooDzZE0Kz5",
        "outputId": "71a3d1e3-27f3-4fb5-d426-2eb02a6c6766"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-20 09:38:14.487 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.489 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.490 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.492 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.492 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.493 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.494 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.495 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.496 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.496 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.497 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.498 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.499 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.499 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.500 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.501 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.501 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.502 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.502 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.503 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.504 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.505 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.505 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.506 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.506 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.507 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-08-20 09:38:14.507 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}